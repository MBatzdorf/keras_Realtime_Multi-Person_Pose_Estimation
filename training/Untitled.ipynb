{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the best weights...\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Loading dataset /media/marco/0e5afcaa-ae0b-45cb-a2c3-406dfeb96d75/marco/PenPose/keras_Realtime_Multi-Person_Pose_Estimation/dataset/train2017 ...\n",
      "Loading image annot 0/5\n",
      "Loading dataset /media/marco/0e5afcaa-ae0b-45cb-a2c3-406dfeb96d75/marco/PenPose/keras_Realtime_Multi-Person_Pose_Estimation/dataset/val2017 ...\n",
      "Loading image annot 0/5\n",
      "\u001b[32m[0131 12:28:34 @parallel.py:311]\u001b[0m [PrefetchDataZMQ] Will fork a dataflow more than one times. This assumes the datapoints are i.i.d.\n",
      "\u001b[32m[0131 12:28:34 @argtools.py:146]\u001b[0m \u001b[5m\u001b[31mWRN\u001b[0m \"import prctl\" failed! Install python-prctl so that processes can be cleaned with guarantee.\n",
      "Epoch 5/200000\n",
      "3/3 [==============================] - 16s 5s/step - loss: 357.7233 - weight_stage1_L1_loss: 46.0530 - weight_stage1_L2_loss: 44.9126 - weight_stage2_L1_loss: 47.2220 - weight_stage2_L2_loss: 6.6394 - weight_stage3_L1_loss: 47.2272 - weight_stage3_L2_loss: 5.5337 - weight_stage4_L1_loss: 47.2161 - weight_stage4_L2_loss: 5.1143 - weight_stage5_L1_loss: 47.2307 - weight_stage5_L2_loss: 4.3001 - weight_stage6_L1_loss: 47.2336 - weight_stage6_L2_loss: 6.4540 - weight_stage1_L1_acc: 0.0100 - weight_stage1_L2_acc: 0.9983 - weight_stage2_L1_acc: 0.0100 - weight_stage2_L2_acc: 0.9983 - weight_stage3_L1_acc: 0.0100 - weight_stage3_L2_acc: 0.9983 - weight_stage4_L1_acc: 0.0100 - weight_stage4_L2_acc: 0.9983 - weight_stage5_L1_acc: 0.0100 - weight_stage5_L2_acc: 0.9983 - weight_stage6_L1_acc: 0.0100 - weight_stage6_L2_acc: 0.9983                      \n",
      "Epoch 6/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 48.4353 - weight_stage1_L1_loss: 2.1117 - weight_stage1_L2_loss: 7.0341 - weight_stage2_L1_loss: 3.3964 - weight_stage2_L2_loss: 4.8562 - weight_stage3_L1_loss: 3.3954 - weight_stage3_L2_loss: 3.8778 - weight_stage4_L1_loss: 3.3844 - weight_stage4_L2_loss: 3.5070 - weight_stage5_L1_loss: 3.4008 - weight_stage5_L2_loss: 2.7905 - weight_stage6_L1_loss: 3.4028 - weight_stage6_L2_loss: 4.6918 - weight_stage1_L1_acc: 0.0000e+00 - weight_stage1_L2_acc: 0.9989 - weight_stage2_L1_acc: 0.0000e+00 - weight_stage2_L2_acc: 0.9989 - weight_stage3_L1_acc: 0.0000e+00 - weight_stage3_L2_acc: 0.9989 - weight_stage4_L1_acc: 0.0000e+00 - weight_stage4_L2_acc: 0.9989 - weight_stage5_L1_acc: 0.0000e+00 - weight_stage5_L2_acc: 0.9989 - weight_stage6_L1_acc: 0.0000e+00 - weight_stage6_L2_acc: 0.9989\n",
      "Epoch 7/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 49.0172 - weight_stage1_L1_loss: 0.3426 - weight_stage1_L2_loss: 27.0014 - weight_stage2_L1_loss: 1.6878 - weight_stage2_L2_loss: 2.9011 - weight_stage3_L1_loss: 1.6901 - weight_stage3_L2_loss: 2.0732 - weight_stage4_L1_loss: 1.6815 - weight_stage4_L2_loss: 1.7594 - weight_stage5_L1_loss: 1.6926 - weight_stage5_L2_loss: 1.1476 - weight_stage6_L1_loss: 1.6923 - weight_stage6_L2_loss: 2.7613 - weight_stage1_L1_acc: 0.0000e+00 - weight_stage1_L2_acc: 1.0000 - weight_stage2_L1_acc: 0.0000e+00 - weight_stage2_L2_acc: 1.0000 - weight_stage3_L1_acc: 0.0000e+00 - weight_stage3_L2_acc: 1.0000 - weight_stage4_L1_acc: 0.0000e+00 - weight_stage4_L2_acc: 1.0000 - weight_stage5_L1_acc: 0.0000e+00 - weight_stage5_L2_acc: 1.0000 - weight_stage6_L1_acc: 0.0000e+00 - weight_stage6_L2_acc: 1.0000\n",
      "Epoch 8/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 22.2128 - weight_stage1_L1_loss: 0.1606 - weight_stage1_L2_loss: 5.7125 - weight_stage2_L1_loss: 1.3087 - weight_stage2_L2_loss: 1.9578 - weight_stage3_L1_loss: 1.3092 - weight_stage3_L2_loss: 1.4050 - weight_stage4_L1_loss: 1.3036 - weight_stage4_L2_loss: 1.1944 - weight_stage5_L1_loss: 1.3121 - weight_stage5_L2_loss: 0.7881 - weight_stage6_L1_loss: 1.3099 - weight_stage6_L2_loss: 1.8646 - weight_stage1_L1_acc: 0.0000e+00 - weight_stage1_L2_acc: 1.0000 - weight_stage2_L1_acc: 0.0000e+00 - weight_stage2_L2_acc: 1.0000 - weight_stage3_L1_acc: 0.0000e+00 - weight_stage3_L2_acc: 1.0000 - weight_stage4_L1_acc: 0.0000e+00 - weight_stage4_L2_acc: 1.0000 - weight_stage5_L1_acc: 0.0000e+00 - weight_stage5_L2_acc: 1.0000 - weight_stage6_L1_acc: 0.0000e+00 - weight_stage6_L2_acc: 1.0000\n",
      "Epoch 9/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 122.9772 - weight_stage1_L1_loss: 16.5330 - weight_stage1_L2_loss: 9.4854 - weight_stage2_L1_loss: 17.1583 - weight_stage2_L2_loss: 2.0232 - weight_stage3_L1_loss: 17.1592 - weight_stage3_L2_loss: 1.6962 - weight_stage4_L1_loss: 17.1546 - weight_stage4_L2_loss: 1.5692 - weight_stage5_L1_loss: 17.1626 - weight_stage5_L2_loss: 1.3280 - weight_stage6_L1_loss: 17.1527 - weight_stage6_L2_loss: 1.9684 - weight_stage1_L1_acc: 0.0000e+00 - weight_stage1_L2_acc: 0.9996 - weight_stage2_L1_acc: 0.0000e+00 - weight_stage2_L2_acc: 0.9996 - weight_stage3_L1_acc: 0.0000e+00 - weight_stage3_L2_acc: 0.9996 - weight_stage4_L1_acc: 0.0000e+00 - weight_stage4_L2_acc: 0.9996 - weight_stage5_L1_acc: 0.0000e+00 - weight_stage5_L2_acc: 0.9996 - weight_stage6_L1_acc: 0.0000e+00 - weight_stage6_L2_acc: 0.9996\n",
      "Epoch 10/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 310.2752 - weight_stage1_L1_loss: 41.9531 - weight_stage1_L2_loss: 12.2874 - weight_stage2_L1_loss: 45.3063 - weight_stage2_L2_loss: 5.6250 - weight_stage3_L1_loss: 45.3096 - weight_stage3_L2_loss: 5.3703 - weight_stage4_L1_loss: 45.3003 - weight_stage4_L2_loss: 5.2674 - weight_stage5_L1_loss: 45.3137 - weight_stage5_L2_loss: 5.0722 - weight_stage6_L1_loss: 45.3021 - weight_stage6_L2_loss: 5.5814 - weight_stage1_L1_acc: 0.0000e+00 - weight_stage1_L2_acc: 0.9972 - weight_stage2_L1_acc: 0.0091 - weight_stage2_L2_acc: 0.9972 - weight_stage3_L1_acc: 0.0091 - weight_stage3_L2_acc: 0.9972 - weight_stage4_L1_acc: 0.0091 - weight_stage4_L2_acc: 0.9972 - weight_stage5_L1_acc: 0.0091 - weight_stage5_L2_acc: 0.9972 - weight_stage6_L1_acc: 0.0091 - weight_stage6_L2_acc: 0.9972   \n",
      "Epoch 11/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 142.7402 - weight_stage1_L1_loss: 19.2565 - weight_stage1_L2_loss: 3.6611 - weight_stage2_L1_loss: 20.3746 - weight_stage2_L2_loss: 3.2403 - weight_stage3_L1_loss: 20.3744 - weight_stage3_L2_loss: 3.0623 - weight_stage4_L1_loss: 20.3719 - weight_stage4_L2_loss: 2.9933 - weight_stage5_L1_loss: 20.3783 - weight_stage5_L2_loss: 2.8609 - weight_stage6_L1_loss: 20.3714 - weight_stage6_L2_loss: 3.2089 - weight_stage1_L1_acc: 0.0000e+00 - weight_stage1_L2_acc: 0.9984 - weight_stage2_L1_acc: 5.2510e-05 - weight_stage2_L2_acc: 0.9984 - weight_stage3_L1_acc: 5.2510e-05 - weight_stage3_L2_acc: 0.9984 - weight_stage4_L1_acc: 5.2510e-05 - weight_stage4_L2_acc: 0.9984 - weight_stage5_L1_acc: 5.2510e-05 - weight_stage5_L2_acc: 0.9984 - weight_stage6_L1_acc: 5.2510e-05 - weight_stage6_L2_acc: 0.9984\n",
      "Epoch 12/200000\n",
      "3/3 [==============================] - 4s 1s/step - loss: 189.8734 - weight_stage1_L1_loss: 27.1342 - weight_stage1_L2_loss: 6.8575 - weight_stage2_L1_loss: 28.5910 - weight_stage2_L2_loss: 2.2396 - weight_stage3_L1_loss: 28.5887 - weight_stage3_L2_loss: 2.0605 - weight_stage4_L1_loss: 28.5850 - weight_stage4_L2_loss: 1.9897 - weight_stage5_L1_loss: 28.5929 - weight_stage5_L2_loss: 1.8534 - weight_stage6_L1_loss: 28.5866 - weight_stage6_L2_loss: 2.2079 - weight_stage1_L1_acc: 0.0049 - weight_stage1_L2_acc: 0.9991 - weight_stage2_L1_acc: 0.0020 - weight_stage2_L2_acc: 0.9991 - weight_stage3_L1_acc: 0.0020 - weight_stage3_L2_acc: 0.9991 - weight_stage4_L1_acc: 0.0020 - weight_stage4_L2_acc: 0.9991 - weight_stage5_L1_acc: 0.0020 - weight_stage5_L2_acc: 0.9991 - weight_stage6_L1_acc: 0.0020 - weight_stage6_L2_acc: 0.9991                 \n",
      "Epoch 13/200000\n"
     ]
    }
   ],
   "source": [
    "%run 'train_pose.py'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
